{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference_and_validation.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "KggxO6EocSRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference and Validation\n",
        "\n",
        "Now that you have a trained network, you can use it for making predictions. This is typically called **inference**, a term borrowed from statistics. However, neural networks have a tendency to perform *too well* on the training data and aren't able to generalize to data that hasn't been seen before. This is called **overfitting** and it impairs inference performance. To test for overfitting while training, we measure the performance on data not in the training set called the **validation** set. We avoid overfitting through regularization such as dropout while monitoring the validation performance during training. In this notebook, we'll see how to do this in PyTorch. \n",
        "\n",
        "As usual, let's start by loading the dataset through torchvision. This time we'll be taking advantage of the test set which you can get by setting `train=False` here:\n",
        "\n",
        "```python\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "```\n",
        "\n",
        "The test set contains images just like the training set. Typically you'll see 10-20% of the original dataset held out for testing and validation with the rest being used for training."
      ]
    },
    {
      "metadata": {
        "id": "cUvBog4-cSRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5e4c12f8-6a05-4e8a-db49-ef726a4ed572"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8SRV0UwcSSA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mGldhhEgcSSS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of validation is to measure the model's performance on data that isn't part of the training set. Performance here is up to the developer to define though. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
      ]
    },
    {
      "metadata": {
        "id": "UTGmCbUWcSSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Classifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sk-yJcOYcSSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d9e3af7-642b-43ec-b8ad-89071e187b6f"
      },
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(testloader))\n",
        "# Get the class probabilities\n",
        "ps = torch.exp(model(images))\n",
        "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
        "print(ps.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wtTq6bJacSTB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With the probabilities, we can get the most likely class using the `ps.topk` method. This returns the $k$ highest values. Since we just want the most likely class, we can use `ps.topk(1)`. This returns a tuple of the top-$k$ values and the top-$k$ indices. If the highest value is the fifth element, we'll get back 4 as the index."
      ]
    },
    {
      "metadata": {
        "id": "lMPwsDnCcSTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "2de8ad57-9af6-4854-d679-f7222730adfd"
      },
      "cell_type": "code",
      "source": [
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "# Look at the most likely classes for the first 10 examples\n",
        "print(top_class[:10,:])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrNsFBR9cSTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can check if the predicted classes match the labels. This is simple to do by equating `top_class` and `labels`, but we have to be careful of the shapes. Here `top_class` is a 2D tensor with shape `(64, 1)` while `labels` is 1D with shape `(64)`. To get the equality to work out the way we want, `top_class` and `labels` must have the same shape.\n",
        "\n",
        "If we do\n",
        "\n",
        "```python\n",
        "equals = top_class == labels\n",
        "```\n",
        "\n",
        "`equals` will have shape `(64, 64)`, try it yourself. What it's doing is comparing the one element in each row of `top_class` with each element in `labels` which returns 64 True/False boolean values for each row."
      ]
    },
    {
      "metadata": {
        "id": "DmlwYC_tcSTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "equals = top_class == labels.view(*top_class.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WnShLAF9cST0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to calculate the percentage of correct predictions. `equals` has binary values, either 0 or 1. This means that if we just sum up all the values and divide by the number of values, we get the percentage of correct predictions. This is the same operation as taking the mean, so we can get the accuracy with a call to `torch.mean`. If only it was that simple. If you try `torch.mean(equals)`, you'll get an error\n",
        "\n",
        "```\n",
        "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
        "```\n",
        "\n",
        "This happens because `equals` has type `torch.ByteTensor` but `torch.mean` isn't implemented for tensors with that type. So we'll need to convert `equals` to a float tensor. Note that when we take `torch.mean` it returns a scalar tensor, to get the actual value as a float we'll need to do `accuracy.item()`."
      ]
    },
    {
      "metadata": {
        "id": "Q1gnIrf2cST7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd8557b9-2ff2-4ad2-fda5-a1110f5af4b0"
      },
      "cell_type": "code",
      "source": [
        "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "print(f'Accuracy: {accuracy.item()*100}%')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 9.375%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X9SVrvN6cSUf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The network is untrained so it's making random guesses and we should see an accuracy around 10%. Now let's train our network and include our validation pass so we can measure how well the network is performing on the test set. Since we're not updating our parameters in the validation pass, we can speed up our code by turning off gradients using `torch.no_grad()`:\n",
        "\n",
        "```python\n",
        "# turn off gradients\n",
        "with torch.no_grad():\n",
        "    # validation pass here\n",
        "    for images, labels in testloader:\n",
        "        ...\n",
        "```\n",
        "\n",
        ">**Exercise:** Implement the validation loop below and print out the total accuracy after the loop. You should be able to get an accuracy above 80%."
      ]
    },
    {
      "metadata": {
        "id": "QPN-82MMcSUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "e4a3772b-e71b-4eaa-fd10-469ea15c4833"
      },
      "cell_type": "code",
      "source": [
        "model = Classifier()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 30\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Validation pass\n",
        "            for images, labels in testloader:\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            \n",
        "            # Append our results to the list\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))\n",
        "            \n",
        "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30..  Training Loss: 0.515..  Test Loss: 0.439..  Test Accuracy: 0.837\n",
            "Epoch: 2/30..  Training Loss: 0.390..  Test Loss: 0.413..  Test Accuracy: 0.853\n",
            "Epoch: 3/30..  Training Loss: 0.355..  Test Loss: 0.400..  Test Accuracy: 0.860\n",
            "Epoch: 4/30..  Training Loss: 0.336..  Test Loss: 0.401..  Test Accuracy: 0.860\n",
            "Epoch: 5/30..  Training Loss: 0.316..  Test Loss: 0.392..  Test Accuracy: 0.856\n",
            "Epoch: 6/30..  Training Loss: 0.303..  Test Loss: 0.405..  Test Accuracy: 0.864\n",
            "Epoch: 7/30..  Training Loss: 0.294..  Test Loss: 0.373..  Test Accuracy: 0.875\n",
            "Epoch: 8/30..  Training Loss: 0.287..  Test Loss: 0.373..  Test Accuracy: 0.875\n",
            "Epoch: 9/30..  Training Loss: 0.276..  Test Loss: 0.367..  Test Accuracy: 0.875\n",
            "Epoch: 10/30..  Training Loss: 0.265..  Test Loss: 0.366..  Test Accuracy: 0.874\n",
            "Epoch: 11/30..  Training Loss: 0.258..  Test Loss: 0.343..  Test Accuracy: 0.883\n",
            "Epoch: 12/30..  Training Loss: 0.252..  Test Loss: 0.361..  Test Accuracy: 0.876\n",
            "Epoch: 13/30..  Training Loss: 0.250..  Test Loss: 0.374..  Test Accuracy: 0.880\n",
            "Epoch: 14/30..  Training Loss: 0.237..  Test Loss: 0.373..  Test Accuracy: 0.872\n",
            "Epoch: 15/30..  Training Loss: 0.235..  Test Loss: 0.356..  Test Accuracy: 0.883\n",
            "Epoch: 16/30..  Training Loss: 0.230..  Test Loss: 0.377..  Test Accuracy: 0.874\n",
            "Epoch: 17/30..  Training Loss: 0.226..  Test Loss: 0.389..  Test Accuracy: 0.878\n",
            "Epoch: 18/30..  Training Loss: 0.223..  Test Loss: 0.404..  Test Accuracy: 0.878\n",
            "Epoch: 19/30..  Training Loss: 0.220..  Test Loss: 0.374..  Test Accuracy: 0.886\n",
            "Epoch: 20/30..  Training Loss: 0.213..  Test Loss: 0.371..  Test Accuracy: 0.885\n",
            "Epoch: 21/30..  Training Loss: 0.212..  Test Loss: 0.386..  Test Accuracy: 0.879\n",
            "Epoch: 22/30..  Training Loss: 0.206..  Test Loss: 0.393..  Test Accuracy: 0.884\n",
            "Epoch: 23/30..  Training Loss: 0.201..  Test Loss: 0.385..  Test Accuracy: 0.886\n",
            "Epoch: 24/30..  Training Loss: 0.199..  Test Loss: 0.435..  Test Accuracy: 0.878\n",
            "Epoch: 25/30..  Training Loss: 0.200..  Test Loss: 0.403..  Test Accuracy: 0.877\n",
            "Epoch: 26/30..  Training Loss: 0.200..  Test Loss: 0.391..  Test Accuracy: 0.886\n",
            "Epoch: 27/30..  Training Loss: 0.192..  Test Loss: 0.399..  Test Accuracy: 0.884\n",
            "Epoch: 28/30..  Training Loss: 0.185..  Test Loss: 0.391..  Test Accuracy: 0.888\n",
            "Epoch: 29/30..  Training Loss: 0.190..  Test Loss: 0.393..  Test Accuracy: 0.881\n",
            "Epoch: 30/30..  Training Loss: 0.181..  Test Loss: 0.392..  Test Accuracy: 0.885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UYhEUPwmcSU0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}